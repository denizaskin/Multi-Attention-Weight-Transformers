{"columns": ["Rank", "Passage", "Score", "Relevant"], "data": [[1, "Algorithms for Inverse Reinforcement Learning", "0.8069", "\u2713"], [2, "Maximum Entropy Inverse Reinforcement Learning", "-0.0469", "\u2713"], [3, "Determining the effectiveness of prompts for self-regulated learning in problem-solving scenarios", "-2.6230", "\u2717"], [4, "Learning to search: Functional gradient techniques for imitation learning", "-2.8649", "\u2713"], [5, "Synchronising movements with the sounds of a virtual partner enhances partner likeability", "-2.9201", "\u2717"], [6, "To recognize shapes, first learn to generate images.", "-2.9439", "\u2717"], [7, "Voltage buffer compensation using Flipped Voltage Follower in a two-stage CMOS op-amp", "-3.0066", "\u2717"], [8, "Audio-visual emotion recognition : A dynamic , multimodal approach", "-3.0900", "\u2717"], [9, "Fast Supervised Discrete Hashing", "-3.1116", "\u2717"], [10, "Learning Agents for Uncertain Environments (Extended Abstract)", "-3.1819", "\u2713"]]}